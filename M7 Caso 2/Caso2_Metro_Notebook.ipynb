{"cells":[{"cell_type":"markdown","id":"e071ac6f","metadata":{"id":"e071ac6f"},"source":["# Caso 2 · Metro de Santiago con PySpark\n","**Muestra reducida + Streaming simulado + KMeans (MLlib)**"]},{"cell_type":"code","source":["# Instalar PySpark en el Entorno de Colab\n","!pip install -q pyspark"],"metadata":{"id":"BVgGjmD6nOip","executionInfo":{"status":"ok","timestamp":1757977390716,"user_tz":180,"elapsed":11921,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}}},"id":"BVgGjmD6nOip","execution_count":1,"outputs":[]},{"cell_type":"markdown","id":"979ad954","metadata":{"id":"979ad954"},"source":["### 1) Inicialización de Spark"]},{"cell_type":"code","execution_count":2,"id":"b60d8500","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b60d8500","executionInfo":{"status":"ok","timestamp":1757977483254,"user_tz":180,"elapsed":9411,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"6649164a-9bcc-444d-ef8c-918407e2dc5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark version: 3.5.1\n"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Caso2-Metro-PySpark\").getOrCreate()\n","print(\"Spark version:\", spark.version)"]},{"cell_type":"markdown","id":"0cbe48e0","metadata":{"id":"0cbe48e0"},"source":["### 2) Carga del CSV"]},{"cell_type":"code","execution_count":4,"id":"2d6a2188","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2d6a2188","executionInfo":{"status":"ok","timestamp":1757977524693,"user_tz":180,"elapsed":11921,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"492821b4-ef7e-43cf-e239-fe3cf56b77fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filas totales: 200\n","root\n"," |-- id_evento: integer (nullable = true)\n"," |-- linea: string (nullable = true)\n"," |-- estacion: string (nullable = true)\n"," |-- tipo_incidente: string (nullable = true)\n"," |-- duracion_minutos: integer (nullable = true)\n"," |-- hora: timestamp (nullable = true)\n","\n","+---------+-----+--------------+------------------------+----------------+-------------------+\n","|id_evento|linea|estacion      |tipo_incidente          |duracion_minutos|hora               |\n","+---------+-----+--------------+------------------------+----------------+-------------------+\n","|1        |L1   |Baquedano     |Falla eléctrica         |20              |2025-09-15 07:30:00|\n","|2        |L2   |Cal y Canto   |Mantenimiento           |15              |2025-09-15 22:15:00|\n","|3        |L3   |Plaza de Armas|Evacuación              |10              |2025-09-15 14:45:00|\n","|4        |L4   |Las Torres    |Interrupción de servicio|25              |2025-09-15 09:15:00|\n","|5        |L5   |Santa Ana     |Falla eléctrica         |30              |2025-09-15 16:30:00|\n","|6        |L6   |Los Leones    |Retraso                 |15              |2025-09-15 11:00:00|\n","|7        |L4A  |Ñuñoa         |Mantenimiento           |20              |2025-09-15 06:45:00|\n","|8        |L1   |Los Héroes    |Falla eléctrica         |25              |2025-09-15 18:15:00|\n","|9        |L2   |Franklin      |Evacuación              |15              |2025-09-15 13:30:00|\n","|10       |L3   |Irarrázaval   |Interrupción de servicio|20              |2025-09-15 20:00:00|\n","+---------+-----+--------------+------------------------+----------------+-------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","\n","PATH_DATA = \"metro_santiago_200.csv\"\n","df = spark.read.csv(PATH_DATA, header=True, inferSchema=True)\n","print(\"Filas totales:\", df.count())\n","df.printSchema()\n","df.show(10, truncate=False)"]},{"cell_type":"code","execution_count":5,"id":"ada503c3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ada503c3","executionInfo":{"status":"ok","timestamp":1757977529454,"user_tz":180,"elapsed":528,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"6b20e3a8-df78-4ff9-d79d-89ee47872b5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filas muestra: 39\n"]}],"source":["# 2.1 Tomar muestra 20%\n","df_sample = df.sample(False, 0.2, seed=42)\n","print(\"Filas muestra:\", df_sample.count())"]},{"cell_type":"markdown","id":"166e2999","metadata":{"id":"166e2999"},"source":["### 3) RDDs + DataFrames + SQL"]},{"cell_type":"code","execution_count":6,"id":"5b12ad8e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5b12ad8e","executionInfo":{"status":"ok","timestamp":1757977812092,"user_tz":180,"elapsed":3571,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"63041de8-e1db-4337-db8b-a9115661f1e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns: ['id_evento', 'linea', 'estacion', 'tipo_incidente', 'duracion_minutos', 'hora']\n","[('Los Héroes', 5), ('Tobalaba', 2), ('Pajaritos', 3), ('Ñuñoa', 3), ('Franklin', 4), ('Lo Prado', 3), ('Vicente Valdés', 4), ('Plaza de Armas', 3), ('Cerrillos', 3), ('Plaza Egaña', 2)]\n","+-----+-----+\n","|linea|total|\n","+-----+-----+\n","|   L6|    7|\n","|   L1|    7|\n","|   L2|    7|\n","|   L3|    6|\n","|   L5|    5|\n","|   L4|    4|\n","|  L4A|    3|\n","+-----+-----+\n","\n"]}],"source":["rdd = df_sample.rdd\n","cols = df_sample.columns\n","print(\"Columns:\", cols)\n","if \"estacion\" in cols:\n","    print(rdd.map(lambda r: (r['estacion'],1)).reduceByKey(lambda a,b:a+b).take(10))\n","\n","df_sample.createOrReplaceTempView(\"metro\")\n","if \"linea\" in cols and \"estacion\" in cols:\n","    spark.sql(\"SELECT linea, COUNT(*) AS total FROM metro GROUP BY linea ORDER BY total DESC\").show()"]},{"cell_type":"markdown","id":"05fe83dd","metadata":{"id":"05fe83dd"},"source":["### 4) MLlib – KMeans"]},{"cell_type":"code","execution_count":7,"id":"798a257b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"798a257b","executionInfo":{"status":"ok","timestamp":1757979817134,"user_tz":180,"elapsed":8608,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"50887d96-d0dd-4735-8ad2-e8e799ef7652"},"outputs":[{"output_type":"stream","name":"stdout","text":["Silhouette (k=3): 0.5206044606009212\n","0 [2.74958796 4.01356396]\n","1 [1.55186585 5.60226636]\n","2 [0.78588079 4.12505185]\n"]}],"source":["from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.evaluation import ClusteringEvaluator\n","\n","num_cols = [c for (c,t) in df_sample.dtypes if t in [\"int\",\"bigint\",\"double\",\"float\"]]\n","if len(num_cols) < 2 and \"estacion\" in df_sample.columns:\n","    feats = df_sample.groupBy(\"estacion\").agg(count(\"*\").alias(\"freq\"))\n","else:\n","    feats = df_sample.select(*num_cols).dropna()\n","\n","assembler = VectorAssembler(inputCols=[c for c in feats.columns if c != \"estacion\"], outputCol=\"features_raw\")\n","feats_vec = assembler.transform(feats)\n","scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n","feats_std = scaler.fit(feats_vec).transform(feats_vec)\n","\n","kmeans = KMeans(featuresCol=\"features\", k=3, seed=42)\n","model = kmeans.fit(feats_std)\n","pred = model.transform(feats_std)\n","\n","evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"prediction\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n","sil = evaluator.evaluate(pred)\n","print(\"Silhouette (k=3):\", sil)\n","for i,c in enumerate(model.clusterCenters()): print(i,c)"]},{"cell_type":"markdown","id":"a728c8ab","metadata":{"id":"a728c8ab"},"source":["### 5) Streaming simulado"]},{"cell_type":"code","execution_count":23,"id":"503a5f54","metadata":{"id":"503a5f54","executionInfo":{"status":"ok","timestamp":1757980429672,"user_tz":180,"elapsed":520,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}}},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n","schema = StructType([\n","    StructField(\"timestamp\", TimestampType(), True),\n","    StructField(\"linea\", StringType(), True),\n","    StructField(\"estacion\", StringType(), True),\n","    StructField(\"afluencia\", IntegerType(), True),\n","])\n","stream_path = \"stream_inputs\"\n","df_stream = spark.readStream.schema(schema).option(\"maxFilesPerTrigger\", 1).csv(stream_path)\n","agg = (df_stream.withWatermark(\"timestamp\",\"10 minutes\")\n","       .groupBy(window(col(\"timestamp\"), \"5 minutes\"), col(\"estacion\"))\n","       .agg(sum(\"afluencia\").alias(\"pasajeros\"))\n","       )\n","query = (agg.writeStream.outputMode(\"update\").format(\"console\").option(\"truncate\", False).start())\n","# Para detener la query: query.stop()"]},{"cell_type":"markdown","source":["### 6) Analizar el flujo de datos entrantes"],"metadata":{"id":"ifOFVHCRydPu"},"id":"ifOFVHCRydPu"},{"cell_type":"code","source":["# Contar eventos por estación en ventanas de 5 minutos\n","from pyspark.sql.functions import window, count\n","\n","# define una agregación de ventana de tiempo\n","stream_analysis = (df_stream\n","                   .withWatermark(\"timestamp\", \"10 minutes\") # Define marca de agua para gestionar datos tardíos\n","                   .groupBy(window(\"timestamp\", \"5 minutes\"), \"estacion\") # Agrupar por ventana de 5 minutos y estación\n","                   .agg(count(\"*\").alias(\"event_count\")) # Contar eventos en cada grupo\n","                  )\n","\n","# Inicia consulta de streaming para mostrar los resultados en la consola\n","query_analysis = (stream_analysis\n","                  .writeStream\n","                  .outputMode(\"update\") # mostrar los recuentos actualizados\n","                  .format(\"console\")\n","                  .option(\"truncate\", False)\n","                  .start())\n","\n","# Para detener la query: query_analysis.stop()"],"metadata":{"id":"abhm11ktyXe1","executionInfo":{"status":"ok","timestamp":1757980650543,"user_tz":180,"elapsed":208,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}}},"id":"abhm11ktyXe1","execution_count":25,"outputs":[]},{"cell_type":"markdown","id":"a5b6fb1b","metadata":{"id":"a5b6fb1b"},"source":["### 7) Exportar artefactos"]},{"cell_type":"code","execution_count":26,"id":"733ffdd2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"733ffdd2","executionInfo":{"status":"ok","timestamp":1757980661309,"user_tz":180,"elapsed":8114,"user":{"displayName":"Hans Contreras","userId":"07919408926789971342"}},"outputId":"b042759b-250d-483e-d14c-85188e7aaada"},"outputs":[{"output_type":"stream","name":"stdout","text":["Guardado silhouette y modelo en artifacts/ y models/\n"]}],"source":["import os, json\n","os.makedirs(\"artifacts\", exist_ok=True)\n","with open(\"artifacts/caso2_metrics.json\",\"w\") as f:\n","    json.dump({\"silhouette_k3\": float(sil)}, f, indent=2)\n","model.write().overwrite().save(\"models/caso2_kmeans\")\n","print(\"Guardado silhouette y modelo en artifacts/ y models/\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}